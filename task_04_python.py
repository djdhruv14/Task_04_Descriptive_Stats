# -*- coding: utf-8 -*-
"""task 04_Python.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/18b57JhX6v9mTL-D9vWfUljUSoyBI9fZf
"""

#1 Using facebook ads dataset
import csv
import math
import statistics
from collections import Counter, defaultdict


def read_csv(filepath):
    """Read CSV file and return list of dict rows."""
    with open(filepath, newline='', encoding='utf-8') as f:
        reader = csv.DictReader(f)
        return list(reader)

import csv
import statistics
from collections import Counter

def read_csv(path):
    with open(path, newline='', encoding='utf-8') as f:
        return list(csv.DictReader(f))

def is_numeric(vals):
    for v in vals:
        if v in (None, ''):
            continue
        try:
            float(v)
        except ValueError:
            return False
    return True

def to_floats(vals):
    nums = []
    for v in vals:
        if v in (None, ''):
            continue
        try:
            nums.append(float(v))
        except ValueError:
            pass
    return nums

def column_stats(rows):
    if not rows:
        return {}
    cols = list(rows[0].keys())
    stats = {}

    for col in cols:
        # gather non-empty values
        vals = [r[col] for r in rows if r.get(col) not in (None, '')]
        col_stat = {'count': len(vals)}

        if is_numeric(vals):
            nums = to_floats(vals)
            if nums:
                col_stat.update({
                    'mean': statistics.mean(nums),
                    'min': min(nums),
                    'max': max(nums),
                    'stdev': statistics.stdev(nums) if len(nums) > 1 else 0.0
                })
            else:
                col_stat.update({'mean': None, 'min': None, 'max': None, 'stdev': None})
        else:
            ctr = Counter(vals)
            col_stat.update({
                'unique_values': len(ctr),
                'most_common': ctr.most_common(5)
            })

        stats[col] = col_stat

    # overall dataset summary
    stats['__dataset__'] = {
        'total_rows': len(rows),
        'total_columns': len(cols)
    }
    return stats

def main():
    filepath = '2024_fb_ads_president_scored_anon.csv'
    try:
        data = read_csv(filepath)
    except FileNotFoundError:
        print(f"Error: file not found at {filepath}")
        return

    if not data:
        print("No rows loaded.")
        return

    stats = column_stats(data)
    # pretty-print
    for col, stat in stats.items():
        print(f"\n=== {col} ===")
        for k, v in stat.items():
            print(f"  {k}: {v}")

if __name__ == '__main__':
    main()

#!/usr/bin/env python3
"""
Summary stats + grouped analysis for a CSV using pure Python syntax

- Per-column: count, mean/min/max/stdev (numeric) OR unique count + top 5 (non-numeric)
- Groups: overall, by page_id, and by (page_id, ad_id)
"""

import csv
import statistics
from collections import Counter, defaultdict

def read_csv(path):
    with open(path, newline='', encoding='utf-8') as f:
        return list(csv.DictReader(f))

def is_numeric(vals):
    for v in vals:
        if v in (None, ''):
            continue
        try:
            float(v)
        except ValueError:
            return False
    return True

def to_floats(vals):
    nums = []
    for v in vals:
        if v in (None, ''):
            continue
        try:
            nums.append(float(v))
        except ValueError:
            pass
    return nums

def column_stats(rows):
    if not rows:
        return {}
    cols = list(rows[0].keys())
    stats = {}
    for col in cols:
        vals = [r[col] for r in rows if r.get(col) not in (None, '')]
        col_stat = {'count': len(vals)}
        if is_numeric(vals):
            nums = to_floats(vals)
            if nums:
                col_stat.update({
                    'mean':    statistics.mean(nums),
                    'min':     min(nums),
                    'max':     max(nums),
                    'stdev':   statistics.stdev(nums) if len(nums) > 1 else 0.0
                })
            else:
                col_stat.update({'mean': None, 'min': None, 'max': None, 'stdev': None})
        else:
            ctr = Counter(vals)
            col_stat.update({
                'unique_values': len(ctr),
                'most_common':   ctr.most_common(5)
            })
        stats[col] = col_stat

    # add overall dataset summary
    stats['__dataset__'] = {
        'total_rows':    len(rows),
        'total_columns': len(cols)
    }
    return stats

def group_by(rows, keys):
    groups = defaultdict(list)
    for r in rows:
        if isinstance(keys, (list, tuple)):
            grp = tuple(r[k] for k in keys)
        else:
            grp = r[keys]
        groups[grp].append(r)
    return groups

def print_stats(title, stats):
    print(f"\n=== {title} ===")
    for key, st in stats.items():
        print(f"\n[{key}]")
        for k, v in st.items():
            print(f"  {k}: {v}")

def main():
    path = '2024_fb_ads_president_scored_anon.csv'
    try:
        data = read_csv(path)
    except FileNotFoundError:
        print(f"File not found: {path}")
        return

    if not data:
        print("No data loaded.")
        return

    # 1) Overall
    overall = column_stats(data)
    print_stats('Overall Dataset', overall)

    # 2) By page_id
    for grp, rows in group_by(data, 'page_id').items():
        stats = column_stats(rows)
        print_stats(f"page_id = {grp}", stats)

    # 3) By page_id and ad_id
    for grp, rows in group_by(data, ['page_id', 'ad_id']).items():
        stats = column_stats(rows)
        print_stats(f"page_id, ad_id = {grp}", stats)

if __name__ == '__main__':
    main()

#2 Using facebook posts dataset
#!/usr/bin/env python3
"""
Summary statistics for the 2024_fb_posts_president_scored_anon.csv dataset
(using pure Python, standard library only).

Computes for each column and overall:
- Numeric: count, mean, min, max, standard deviation
- Non-numeric: count, unique value count, top 5 most frequent
- Overall dataset: total rows, total columns
"""

import csv
import statistics
from collections import Counter


def read_csv(path):
    """Load CSV into list of dicts."""
    with open(path, newline='', encoding='utf-8') as f:
        return list(csv.DictReader(f))


def is_numeric(vals):
    """Check if all non-empty values can be parsed to float."""
    for v in vals:
        if v in (None, ''):
            continue
        try:
            float(v)
        except ValueError:
            return False
    return True


def to_floats(vals):
    """Convert values to floats, skipping empties."""
    nums = []
    for v in vals:
        if v in (None, ''):
            continue
        try:
            nums.append(float(v))
        except ValueError:
            pass
    return nums


def column_stats(rows):
    """Compute stats for each column in rows."""
    if not rows:
        return {}
    cols = list(rows[0].keys())
    stats = {}

    for col in cols:
        vals = [r[col] for r in rows if r.get(col) not in (None, '')]
        col_stat = {'count': len(vals)}
        if is_numeric(vals):
            nums = to_floats(vals)
            if nums:
                col_stat.update({
                    'mean': statistics.mean(nums),
                    'min': min(nums),
                    'max': max(nums),
                    'stdev': statistics.stdev(nums) if len(nums) > 1 else 0.0
                })
            else:
                col_stat.update({'mean': None, 'min': None, 'max': None, 'stdev': None})
        else:
            ctr = Counter(vals)
            col_stat.update({
                'unique_values': len(ctr),
                'most_common': ctr.most_common(5)
            })
        stats[col] = col_stat

    # overall dataset
    stats['__dataset__'] = {
        'total_rows': len(rows),
        'total_columns': len(cols)
    }
    return stats


def main():
    # Path to the posts dataset
    path = '2024_fb_posts_president_scored_anon.csv'
    try:
        data = read_csv(path)
    except FileNotFoundError:
        print(f"Error: file not found at {path}")
        return

    stats = column_stats(data)

    # Print results
    for col, st in stats.items():
        print(f"\n=== {col} ===")
        for k, v in st.items():
            print(f"  {k}: {v}")

if __name__ == '__main__':
    main()

#!/usr/bin/env python3
"""
Summary statistics + grouped analysis for the
2024_fb_posts_president_scored_anon.csv dataset
(using pure Python, standard library only).

Computes for each column and overall:
- Numeric: count, mean, min, max, stdev
- Non-numeric: count, unique value count, top 5 most frequent
- Overall dataset: total rows, total columns

Then attempts the same stats:
- Grouped by page_id (if present)
- Grouped by (page_id, ad_id) (if both present)
"""

import csv
import statistics
from collections import Counter, defaultdict


def read_csv(path):
    """Load CSV into list of dicts."""
    with open(path, newline='', encoding='utf-8') as f:
        return list(csv.DictReader(f))


def is_numeric(vals):
    """Check if all non-empty values can be parsed to float."""
    for v in vals:
        if v in (None, ''):
            continue
        try:
            float(v)
        except ValueError:
            return False
    return True


def to_floats(vals):
    """Convert values to floats, skipping empties."""
    nums = []
    for v in vals:
        if v in (None, ''):
            continue
        try:
            nums.append(float(v))
        except ValueError:
            pass
    return nums


def column_stats(rows):
    """Compute stats for each column in rows."""
    if not rows:
        return {}
    cols = list(rows[0].keys())
    stats = {}

    for col in cols:
        vals = [r[col] for r in rows if r.get(col) not in (None, '')]
        col_stat = {'count': len(vals)}
        if is_numeric(vals):
            nums = to_floats(vals)
            if nums:
                col_stat.update({
                    'mean':    statistics.mean(nums),
                    'min':     min(nums),
                    'max':     max(nums),
                    'stdev':   statistics.stdev(nums) if len(nums) > 1 else 0.0
                })
            else:
                col_stat.update({'mean': None, 'min': None, 'max': None, 'stdev': None})
        else:
            ctr = Counter(vals)
            col_stat.update({
                'unique_values': len(ctr),
                'most_common':   ctr.most_common(5)
            })
        stats[col] = col_stat

    # overall dataset
    stats['__dataset__'] = {
        'total_rows':    len(rows),
        'total_columns': len(cols)
    }
    return stats


def group_by(rows, keys):
    """Group rows by a single key or tuple of keys."""
    groups = defaultdict(list)
    for r in rows:
        if isinstance(keys, (list, tuple)):
            grp_key = tuple(r[k] for k in keys)
        else:
            grp_key = r[keys]
        groups[grp_key].append(r)
    return groups


def print_stats(title, stats):
    """Print computed stats with a header."""
    print(f"\n=== {title} ===")
    for key, st in stats.items():
        print(f"\n[{key}]")
        for k, v in st.items():
            print(f"  {k}: {v}")


def main():
    path = '2024_fb_posts_president_scored_anon.csv'
    try:
        data = read_csv(path)
    except FileNotFoundError:
        print(f"Error: file not found: {path}")
        return

    if not data:
        print("No data loaded.")
        return

    # Print available columns to verify grouping keys
    columns = list(data[0].keys())
    print("Available columns:", columns)

    # Overall stats
    overall = column_stats(data)
    print_stats('Overall Dataset', overall)

    # Group by page_id if present
    if 'page_id' in columns:
        for grp, rows in group_by(data, 'page_id').items():
            stats = column_stats(rows)
            print_stats(f"Group: page_id={grp}", stats)
    else:
        print("\nWarning: 'page_id' column not found. Skipping grouping by page_id.")

    # Group by page_id and ad_id if both present
    if all(k in columns for k in ('page_id', 'ad_id')):
        for grp, rows in group_by(data, ['page_id', 'ad_id']).items():
            stats = column_stats(rows)
            print_stats(f"Group: page_id={grp[0]}, ad_id={grp[1]}", stats)
    else:
        missing = [k for k in ('page_id', 'ad_id') if k not in columns]
        print(f"\nWarning: missing columns {missing}. Skipping grouping by (page_id, ad_id).")

if __name__ == '__main__':
    main()

#3 Using twitter posts dataset
#!/usr/bin/env python3
"""
Summary statistics for the
2024_tw_posts_president_scored_anon.csv dataset
(using pure Python, standard library only).

For each column, computes:
- Numeric: count, mean, min, max, standard deviation
- Non-numeric: count, unique value count, top 5 most frequent values

Also includes an overall dataset summary:
- total rows, total columns
"""

import csv
import statistics
from collections import Counter


def read_csv(path):
    """Load CSV into list of dicts."""
    with open(path, newline='', encoding='utf-8') as f:
        return list(csv.DictReader(f))


def is_numeric(values):
    """Check if all non-empty values can be parsed as float."""
    for v in values:
        if v in (None, ''):
            continue
        try:
            float(v)
        except ValueError:
            return False
    return True


def to_floats(values):
    """Convert non-empty values to floats."""
    nums = []
    for v in values:
        if v in (None, ''):
            continue
        try:
            nums.append(float(v))
        except ValueError:
            pass
    return nums


def column_stats(rows):
    """Compute stats for each column in rows."""
    if not rows:
        return {}
    cols = list(rows[0].keys())
    stats = {}

    for col in cols:
        values = [r[col] for r in rows if r.get(col) not in (None, '')]
        col_stat = {'count': len(values)}

        if is_numeric(values):
            nums = to_floats(values)
            if nums:
                col_stat.update({
                    'mean': statistics.mean(nums),
                    'min': min(nums),
                    'max': max(nums),
                    'stdev': statistics.stdev(nums) if len(nums) > 1 else 0.0
                })
            else:
                col_stat.update({
                    'mean': None,
                    'min': None,
                    'max': None,
                    'stdev': None
                })
        else:
            ctr = Counter(values)
            col_stat.update({
                'unique_values': len(ctr),
                'most_common': ctr.most_common(5)
            })

        stats[col] = col_stat

    # overall summary
    stats['__dataset__'] = {
        'total_rows': len(rows),
        'total_columns': len(cols)
    }
    return stats


def print_stats(stats):
    """Pretty-print the stats dict."""
    for col, st in stats.items():
        print(f"\n=== {col} ===")
        for k, v in st.items():
            print(f"  {k}: {v}")


def main():
    path = '2024_tw_posts_president_scored_anon.csv'
    try:
        data = read_csv(path)
    except FileNotFoundError:
        print(f"Error: file not found at {path}")
        return

    if not data:
        print("No data loaded.")
        return

    stats = column_stats(data)
    print_stats(stats)

if __name__ == '__main__':
    main()

#!/usr/bin/env python3
"""
Summary statistics + grouped analysis for the
2024_tw_posts_president_scored_anon.csv dataset
(using pure Python, standard library only).

For each column:
- Numeric: count, mean, min, max, standard deviation
- Non-numeric: count, unique value count, top 5 most frequent values

Overall dataset summary:
- total rows, total columns

Then repeats the same stats grouped by:
- page_id (if present)
- (page_id, ad_id) (if both present)
"""

import csv
import statistics
from collections import Counter, defaultdict


def read_csv(path):
    """Load CSV into list of dicts."""
    with open(path, newline='', encoding='utf-8') as f:
        return list(csv.DictReader(f))


def is_numeric(values):
    """Check if all non-empty values can be parsed as float."""
    for v in values:
        if v in (None, ''):
            continue
        try:
            float(v)
        except ValueError:
            return False
    return True


def to_floats(values):
    """Convert non-empty values to floats."""
    nums = []
    for v in values:
        if v in (None, ''):
            continue
        try:
            nums.append(float(v))
        except ValueError:
            pass
    return nums


def column_stats(rows):
    """Compute stats for each column in a list of rows."""
    if not rows:
        return {}
    cols = list(rows[0].keys())
    stats = {}
    for col in cols:
        vals = [r[col] for r in rows if r.get(col) not in (None, '')]
        stat = {'count': len(vals)}
        if is_numeric(vals):
            nums = to_floats(vals)
            if nums:
                stat.update({
                    'mean': statistics.mean(nums),
                    'min': min(nums),
                    'max': max(nums),
                    'stdev': statistics.stdev(nums) if len(nums) > 1 else 0.0
                })
            else:
                stat.update({'mean': None, 'min': None, 'max': None, 'stdev': None})
        else:
            ctr = Counter(vals)
            stat.update({
                'unique_values': len(ctr),
                'most_common': ctr.most_common(5)
            })
        stats[col] = stat
    stats['__dataset__'] = {'total_rows': len(rows), 'total_columns': len(cols)}
    return stats


def group_by(rows, keys):
    """Group rows by a single key or tuple of keys."""
    groups = defaultdict(list)
    for r in rows:
        if isinstance(keys, (list, tuple)):
            key = tuple(r[k] for k in keys)
        else:
            key = r[keys]
        groups[key].append(r)
    return groups


def print_stats(title, stats):
    print(f"\n=== {title} ===")
    for col, stat in stats.items():
        print(f"\n[{col}]")
        for k, v in stat.items():
            print(f"  {k}: {v}")


def main():
    path = '2024_tw_posts_president_scored_anon.csv'
    try:
        data = read_csv(path)
    except FileNotFoundError:
        print(f"Error: file not found: {path}")
        return

    if not data:
        print("No data loaded.")
        return

    # Show overall stats
    overall = column_stats(data)
    print_stats('Overall Dataset', overall)

    # Identify available columns
    columns = set(data[0].keys())

    # Group by page_id
    if 'page_id' in columns:
        for group_key, rows in group_by(data, 'page_id').items():
            stats = column_stats(rows)
            print_stats(f"Group: page_id={group_key}", stats)
    else:
        print("\nSkipping page_id grouping: column not found.")

    # Group by page_id and ad_id
    if {'page_id', 'ad_id'}.issubset(columns):
        for group_key, rows in group_by(data, ['page_id', 'ad_id']).items():
            stats = column_stats(rows)
            print_stats(f"Group: page_id={group_key[0]}, ad_id={group_key[1]}", stats)
    else:
        print("\nSkipping (page_id, ad_id) grouping: required columns not found.")

if __name__ == '__main__':
    main()